{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1Mgp4EkDR6TrJLLZQHA3wmmN8IV0SyUy9",
      "authorship_tag": "ABX9TyNDOGJ+/U+XLprXaXOAuIHw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jj-o/Pytorch/blob/main/%EC%84%B1%EB%8A%A5%EC%B5%9C%EC%A0%81%ED%99%94.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DropOut을 이용한 성능 최적화"
      ],
      "metadata": {
        "id": "w7vYus8tyM7K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ1w3blfsUP1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.FashionMNIST(root='/content/drive/MyDrive/Pytorch/chap08/data', train=True, \n",
        "                                        download=True, \n",
        "                                        transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "h4DBehy-tZKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "UW-SBjRIt97q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(images.shape)\n",
        "print(images[0].shape)\n",
        "print(labels[0].item())"
      ],
      "metadata": {
        "id": "6klel-GHuC4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(img, title):    \n",
        "    plt.figure(figsize=(batch_size * 4, 4))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "MIcyLM-yuR7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_batch_images(dataloader):\n",
        "    images, labels = next(iter(dataloader))\n",
        "    \n",
        "    img = torchvision.utils.make_grid(images)\n",
        "    imshow(img, title=[str(x.item()) for x in labels])\n",
        "    \n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "U6vClELbufV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = show_batch_images(trainloader)"
      ],
      "metadata": {
        "id": "aumMKzWPukOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NormalNet(nn.Module):\n",
        "    def __init__(self): \n",
        "        super(NormalNet, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(784, 48),  # 28 x 28 = 784\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 24),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(24, 10)\n",
        "        )\n",
        "             \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Q3Y3_Zuuu0ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BNNet(nn.Module):\n",
        "    def __init__(self): \n",
        "        super(BNNet, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(784, 48),\n",
        "            nn.BatchNorm1d(48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 24),\n",
        "            nn.BatchNorm1d(24),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(24, 10)\n",
        "        )\n",
        "             \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "4RZ9ONlBu0Wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NormalNet().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "0--0EmFXvRf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bn = BNNet().to(device)\n",
        "print(model_bn)"
      ],
      "metadata": {
        "id": "6-5X_wnlvTYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 512\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "pnOmDjfhvduD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "opt = optim.SGD(model.parameters(), lr=0.01)\n",
        "opt_bn = optim.SGD(model_bn.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "d6eivn0NvgTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_arr = []\n",
        "loss_bn_arr = []\n",
        "max_epochs = 20\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        opt.zero_grad()\n",
        "        outputs = model(inputs).to(device)        \n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "        opt_bn.zero_grad()\n",
        "        outputs_bn = model_bn(inputs)\n",
        "        loss_bn = loss_fn(outputs_bn, labels)\n",
        "        loss_bn.backward()\n",
        "        opt_bn.step()\n",
        "        \n",
        "        loss_arr.append(loss.item())\n",
        "        loss_bn_arr.append(loss_bn.item())\n",
        "           \n",
        "    plt.plot(loss_arr, 'yellow', label='Normal')\n",
        "    plt.plot(loss_bn_arr, 'blue', label='BatchNorm')    \n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "6jGqgoyBvk_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 50\n",
        "noise = 0.3\n",
        "\n",
        "x_train = torch.unsqueeze(torch.linspace(-1, 1, N), 1)\n",
        "y_train = x_train + noise * torch.normal(torch.zeros(N, 1), torch.ones(N, 1))\n",
        "#x_train, y_train= x_train.to(device), y_train.to(device)\n",
        "x_test = torch.unsqueeze(torch.linspace(-1, 1, N), 1)\n",
        "y_test = x_test + noise * torch.normal(torch.zeros(N, 1), torch.ones(N, 1))\n",
        "#x_test, y_test = x_test.to(device), y_test.to(device)"
      ],
      "metadata": {
        "id": "aNxoA6O9v9-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x_train.data.numpy(), y_train.data.numpy(), c='purple', alpha=0.5, label='train')\n",
        "plt.scatter(x_test.data.numpy(), y_test.data.numpy(), c='yellow', alpha=0.5, label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gfAafU71wWIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_h = 100\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(1, N_h),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(N_h, N_h),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(N_h, 1),\n",
        ")\n",
        "\n",
        "model_dropout = torch.nn.Sequential(\n",
        "    torch.nn.Linear(1, N_h),\n",
        "    torch.nn.Dropout(0.2),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(N_h, N_h),\n",
        "    torch.nn.Dropout(0.2),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(N_h, 1),\n",
        ")"
      ],
      "metadata": {
        "id": "tgHhUmUFxHxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "opt_dropout = torch.optim.Adam(model_dropout.parameters(), lr=0.01)\n",
        "loss_fn = torch.nn.MSELoss().to(device)"
      ],
      "metadata": {
        "id": "7Ua5wpSHxKho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 1000\n",
        "for epoch in range(max_epochs):    \n",
        "    pred = model(x_train)\n",
        "    loss = loss_fn(pred, y_train)\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    \n",
        "    pred_dropout = model_dropout(x_train)\n",
        "    loss_dropout = loss_fn(pred_dropout, y_train)\n",
        "    opt_dropout.zero_grad()\n",
        "    loss_dropout.backward()\n",
        "    opt_dropout.step()    \n",
        "    \n",
        "    if epoch % 50 == 0:        \n",
        "        model.eval()\n",
        "        model_dropout.eval()\n",
        "        \n",
        "        test_pred = model(x_test)\n",
        "        test_loss = loss_fn(test_pred, y_test)\n",
        "        \n",
        "        test_pred_dropout = model_dropout(x_test)\n",
        "        test_loss_dropout = loss_fn(test_pred_dropout, y_test)\n",
        "        \n",
        "        plt.scatter(x_train.data.numpy(), y_train.data.numpy(), c='purple', alpha=0.5, label='train')\n",
        "        plt.scatter(x_test.data.numpy(), y_test.data.numpy(), c='yellow', alpha=0.5, label='test')\n",
        "        plt.plot(x_test.data.numpy(), test_pred.data.numpy(), 'b-', lw=3, label='normal')\n",
        "        plt.plot(x_test.data.numpy(), test_pred_dropout.data.numpy(), 'g--', lw=3,  label='dropout')\n",
        "        \n",
        "        plt.title('Epoch %d, Loss = %0.4f, Loss with dropout = %0.4f' % (epoch, test_loss, test_loss_dropout))\n",
        "        plt.legend()\n",
        "        model.train()\n",
        "        model_dropout.train()        \n",
        "        plt.pause(0.05)"
      ],
      "metadata": {
        "id": "GuldSuhpxT0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#조기 종료를 이용한 성능 최적화"
      ],
      "metadata": {
        "id": "QlbUaRHFyVEe"
      }
    }
  ]
}